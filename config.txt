sin data
a: Ntrain 50 (if nothing try 100) reduce Nepoch 1000 --T_inv 10 
b: --T_inv 5 

NeuralODE+inv+contrasitve: python main.py --task sin  --Ntrain 50 --Nvalid 25 --Ntest 25 --T_in 3 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1000
NeuralODE+inv: python main.py --task sin  --Ntrain 50 --Nvalid 50 --Nvalid 25 --Ntest 25 --T_in 3 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1000 --contr_loss False


NeuralODE: python main.py --task sin  --Ntrain 500 --Nvalid 50 --T_in 10 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 0 --Nepoch 1000 --contr_loss False  

spiral data --> Cagatay checks the data
a: 
b: 
python main.py --task spiral --Ntrain 800 --Nvalid 50 --T_in 8 --T_inv 40 --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 3000
python main.py --task spiral --Ntrain 800 --Nvalid 50 --T_in 8 --T_inv 40 --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 3000 --contr_loss False
python main.py --task spiral --Ntrain 800 --Nvalid 50 --T_in 40 --T_inv 40 --ode_latent_dim 8  --inv_latent_dim 0 --Nepoch 3000 --contr_loss False


lv data
a: --T_inv 40 
b --Ntrain 100

a:
python main.py --task lv --Ntrain 800 --Nvalid 50 --Ntest 50 --T_in 8 --T_inv 40  --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 2000
python main.py --task lv --Ntrain 800 --Nvalid 50 --Ntest 50 --T_in 40 --T_inv 20  --ode_latent_dim 8  --inv_latent_dim 0 --Nepoch 2000 --contr_loss False

python main.py --task lv --Ntrain 800 --Nvalid 50 --T_in 8 --T_inv 20  --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 2000
python main.py --task lv --Ntrain 800 --Nvalid 50 --T_in 8 --T_inv 20  --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 2000 --contr_loss False
python main.py --task lv --Ntrain 800 --Nvalid 50 --T_in 20 --T_inv 20  --ode_latent_dim 8  --inv_latent_dim 0 --Nepoch 2000 --contr_loss False

moving mnist (seq_len specifies that training data uses 15 time frames)
a: check content variable ida 
b: dimensionality of content variable 
python main.py --task mov_mnist --Ntrain 1500 --Nvalid 50 --Ntest 50 --seq_len 15 --cnn_arch dcgan --T_in 5 --T_inv 15 --ode_latent_dim 12 --inv_latent_dim 16 --Nepoch 2500
python main.py --task mov_mnist --Ntrain 1500 --Nvalid 50 --Ntest 50 --seq_len 15 --cnn_arch dcgan --T_in 5 --T_inv 15 --ode_latent_dim 12 --inv_latent_dim 32 --Nepoch 2500
python main.py --task mov_mnist --Ntrain 1500 --Nvalid 50 --Ntest 50 --seq_len 15 --cnn_arch dcgan --T_in 5 --T_inv 15 --ode_latent_dim 12 --inv_latent_dim 64 --Nepoch 2500


python main.py --task mov_mnist --Ntrain 500 --Nvalid 40 --subsample 50 --seq_len 15 --cnn_arch dcgan --T_in 5 --T_inv 15 --Nepoch 2500

rot mnist (WE ARE HAPPY)
python main.py --task rot_mnist --Ntrain 500 --Nvalid 25 --Ntest 25 --cnn_arch cnn  --T_in 1 --T_inv 16 --ode_latent_dim 10 --inv_latent_dim 16 --Nepoch 1000 #result 16-01-2023-15:58
python main.py --task rot_mnist --Ntrain 500 --Nvalid 25 --Ntest 25 --cnn_arch cnn  --T_in 1 --T_inv 16 --ode_latent_dim 10 --inv_latent_dim 16 --Nepoch 1000 --contr_loss False
python main.py --task rot_mnist --Ntrain 500 --Nvalid 25 --Ntest 25 --cnn_arch cnn  --T_in 1 --T_inv 16 --ode_latent_dim 10 --inv_latent_dim 0 --Nepoch 1000 --contr_loss False
change content : few-shot learning 