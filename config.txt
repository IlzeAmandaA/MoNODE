sin data
a: Ntrain 50 (if nothing try 100) reduce Nepoch 1000 --T_inv 10 
b: --T_inv 5 

a: nope too Ntrain
NeuralODE+inv+contrasitve: python main.py --task sin  --Ntrain 50 --Nvalid 25 --Ntest 25 --T_in 3 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1000
NeuralODE+inv: python main.py --task sin  --Ntrain 50 --Nvalid 25 --Nvalid 25 --Ntest 25 --T_in 3 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1000 --contr_loss False
NeuralODE: python main.py --task sin  --Ntrain 50 --Nvalid 25 --Ntest 25 --T_in 10 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 0 --Nepoch 1000 --contr_loss False  

b: nope too short Ninv
NeuralODE+inv+contrasitve: python main.py --task sin  --Ntrain 50 --Nvalid 25 --Ntest 25 --T_in 3 --T_inv 5  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1000
NeuralODE+inv: python main.py --task sin  --Ntrain 50 --Nvalid 50 --Ntest 25 --T_in 3 --T_inv 5  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1000 --contr_loss False
NeuralODE: python main.py --task sin  --Ntrain 50 --Nvalid 25 --Ntest 25 --T_in 5 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 0 --Nepoch 1000 --contr_loss False  

b:1 Ninv 10 Ntrain 80 Epoch 1500
python main.py --task sin  --Ntrain 80 --Nvalid 25 --Ntest 25 --T_in 3 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1500
python main.py --task sin  --Ntrain 80 --Nvalid 25 --Ntest 25 --T_in 3 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1500 --contr_loss False
python main.py --task sin  --Ntrain 80 --Nvalid 25 --Ntest 25 --T_in 10 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 0 --Nepoch 1500 --contr_loss False


c:
python main.py --task sin  --Ntrain 100 --Nvalid 25 --Ntest 25 --T_in 3 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1000
python main.py --task sin  --Ntrain 100 --Nvalid 25 --Ntest 25 --T_in 3 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1000 --contr_loss False
python main.py --task sin  --Ntrain 100 --Nvalid 25 --Ntest 25 --T_in 10 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 0 --Nepoch 1000 --contr_loss False

d:
python main.py --task sin  --Ntrain 100 --Nvalid 25 --Ntest 25 --T_in 3 --T_inv 7  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1000
python main.py --task sin  --Ntrain 100 --Nvalid 25 --Ntest 25 --T_in 3 --T_inv 7  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1000 --contr_loss False
python main.py --task sin  --Ntrain 100 --Nvalid 25 --Ntest 25 --T_in 7 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 0 --Nepoch 1000 --contr_loss False

----------------------------------
spiral data --> Cagatay checks the data
a: 
b: 
python main.py --task spiral --Ntrain 800 --Nvalid 50 --T_in 8 --T_inv 40 --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 3000
python main.py --task spiral --Ntrain 800 --Nvalid 50 --T_in 8 --T_inv 40 --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 3000 --contr_loss False
python main.py --task spiral --Ntrain 800 --Nvalid 50 --T_in 40 --T_inv 40 --ode_latent_dim 8  --inv_latent_dim 0 --Nepoch 3000 --contr_loss False

-----------------------
lv data
a: --Ntrain 500 --T_inv 40 
python main.py --task lv --Ntrain 500 --Nvalid 100 --Ntest 100 --batch_size 20 --T_in 8 --T_inv 40  --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 2000
python main.py --task lv --Ntrain 500 --Nvalid 100 --Ntest 100 --batch_size 20 --T_in 8 --T_inv 40  --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 2000 --contr_loss False
python main.py --task lv --Ntrain 500 --Nvalid 100 --Ntest 100 --batch_size 20 --T_in 40 --T_inv 20  --ode_latent_dim 8  --inv_latent_dim 0 --Nepoch 2000 --contr_loss False

    a:1 --Ntrain 500 --T_inv 20 



b: --Ntrain 100  --T_inv 40 
python main.py --task lv --Ntrain 100 --Nvalid 30 --Ntest 30 --batch_size 10 --T_in 8 --T_inv 40  --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 2000
python main.py --task lv --Ntrain 100 --Nvalid 30 --Ntest 30 --batch_size 10 --T_in 8 --T_inv 40  --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 2000 --contr_loss False
python main.py --task lv --Ntrain 100 --Nvalid 30 --Ntest 30 --batch_size 10 --T_in 40 --T_inv 20  --ode_latent_dim 8  --inv_latent_dim 0 --Nepoch 2000 --contr_loss False

    b:1 --Ntrain 250  --T_inv 40 


c:  --Ntrain 100  --T_inv 20
python main.py --task lv --Ntrain 100 --Nvalid 30 --Ntest 30 --batch_size 10 --T_in 8 --T_inv 20  --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 2000
python main.py --task lv --Ntrain 100 --Nvalid 30 --Ntest 30 --batch_size 10 --T_in 8 --T_inv 20  --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 2000 --contr_loss False
python main.py --task lv --Ntrain 100 --Nvalid 30 --Ntest 30 --batch_size 10 --T_in 20 --T_inv 20  --ode_latent_dim 8  --inv_latent_dim 0 --Nepoch 2000 --contr_loss False

    c:1. --Ntrain 250  --T_inv 20



moving mnist (seq_len specifies that training data uses 15 time frames)
a: check content variable ida 
b: dimensionality of content variable 
python main.py --task mov_mnist --Ntrain 1500 --Nvalid 50 --Ntest 50 --seq_len 15 --cnn_arch dcgan --T_in 5 --T_inv 15 --ode_latent_dim 12 --inv_latent_dim 64 --Nepoch 2000
python main.py --task mov_mnist --Ntrain 1500 --Nvalid 50 --Ntest 50 --seq_len 15 --cnn_arch dcgan --T_in 5 --T_inv 15 --ode_latent_dim 12 --inv_latent_dim 32 --Nepoch 2500
python main.py --task mov_mnist --Ntrain 1500 --Nvalid 50 --Ntest 50 --seq_len 15 --cnn_arch dcgan --T_in 5 --T_inv 15 --ode_latent_dim 12 --inv_latent_dim 64 --Nepoch 2500


python main.py --task mov_mnist --Ntrain 500 --Nvalid 40 --subsample 50 --seq_len 15 --cnn_arch dcgan --T_in 5 --T_inv 15 --Nepoch 2500

rot mnist (WE ARE HAPPY)
python main.py --task rot_mnist --Ntrain 500 --Nvalid 60 --Ntest 60 --batch_size 20 --cnn_arch cnn  --T_in 1 --T_inv 16 --ode_latent_dim 10 --inv_latent_dim 16 --Nepoch 1000 #result 16-01-2023-15:58
python main.py --task rot_mnist --Ntrain 500 --Nvalid 60 --Ntest 60 --batch_size 20 --cnn_arch cnn  --T_in 1 --T_inv 16 --ode_latent_dim 10 --inv_latent_dim 16 --Nepoch 1000 --contr_loss False
python main.py --task rot_mnist --Ntrain 500 --Nvalid 60 --Ntest 60 --batch_size 20 --cnn_arch cnn  --T_in 1 --T_inv 16 --ode_latent_dim 10 --inv_latent_dim 0 --Nepoch 1000 --contr_loss False

b: increase T_in 5 for Neural ODE
python main.py --task rot_mnist --Ntrain 500 --Nvalid 60 --Ntest 60 --batch_size 20 --cnn_arch cnn  --T_in 5 --T_inv 16 --ode_latent_dim 10 --inv_latent_dim 0 --Nepoch 1000 --contr_loss False



change content : few-shot learning 