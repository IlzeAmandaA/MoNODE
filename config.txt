####### SIN ##########
final settings: Ntrain 80 batch_size 10 T_inv 10 
19-01-2023-13:48 : python main.py --task sin  --Ntrain 80 --Nvalid 25 --Ntest 25 --batch_size 10 --T_in 3 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1500
19-01-2023-13:49 : python main.py --task sin  --Ntrain 80 --Nvalid 25 --Ntest 25 --batch_size 10 --T_in 3 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1500 --contr_loss False
19-01-2023-13:50 : python main.py --task sin  --Ntrain 80 --Nvalid 25 --Ntest 25 --batch_size 10 --T_in 10 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 0 --Nepoch 1500 --contr_loss False

try: solver == 'dopri5' 
    python main.py --task sin  --Ntrain 80 --Nvalid 25 --Ntest 25 --batch_size 10 --solver dopri5 --T_in 3 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1500
    python main.py --task sin  --Ntrain 80 --Nvalid 25 --Ntest 25 --batch_size 10 --solver dopri5 --T_in 3 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1500 --contr_loss False
    python main.py --task sin  --Ntrain 80 --Nvalid 25 --Ntest 25 --batch_size 10 --solver dopri5 --T_in 10 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 0 --Nepoch 1500 --contr_loss False

a: nope too Ntrain
NeuralODE+inv+contrasitve: python main.py --task sin  --Ntrain 50 --Nvalid 25 --Ntest 25 --T_in 3 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1000
NeuralODE+inv: python main.py --task sin  --Ntrain 50 --Nvalid 25 --Nvalid 25 --Ntest 25 --T_in 3 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1000 --contr_loss False
NeuralODE: python main.py --task sin  --Ntrain 50 --Nvalid 25 --Ntest 25 --T_in 10 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 0 --Nepoch 1000 --contr_loss False  

b: nope too short Ninv
NeuralODE+inv+contrasitve: python main.py --task sin  --Ntrain 50 --Nvalid 25 --Ntest 25 --T_in 3 --T_inv 5  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1000
NeuralODE+inv: python main.py --task sin  --Ntrain 50 --Nvalid 50 --Ntest 25 --T_in 3 --T_inv 5  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1000 --contr_loss False
NeuralODE: python main.py --task sin  --Ntrain 50 --Nvalid 25 --Ntest 25 --T_in 5 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 0 --Nepoch 1000 --contr_loss False  

b:1 Ninv 10 Ntrain 80 Epoch 1500
python main.py --task sin  --Ntrain 80 --Nvalid 25 --Ntest 25 --T_in 3 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1500
python main.py --task sin  --Ntrain 80 --Nvalid 25 --Ntest 25 --T_in 3 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1500 --contr_loss False
python main.py --task sin  --Ntrain 80 --Nvalid 25 --Ntest 25 --T_in 10 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 0 --Nepoch 1500 --contr_loss False

c:
python main.py --task sin  --Ntrain 100 --Nvalid 25 --Ntest 25 --T_in 3 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1000
python main.py --task sin  --Ntrain 100 --Nvalid 25 --Ntest 25 --T_in 3 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1000 --contr_loss False
python main.py --task sin  --Ntrain 100 --Nvalid 25 --Ntest 25 --T_in 10 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 0 --Nepoch 1000 --contr_loss False

d:
python main.py --task sin  --Ntrain 100 --Nvalid 25 --Ntest 25 --T_in 3 --T_inv 7  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1000
python main.py --task sin  --Ntrain 100 --Nvalid 25 --Ntest 25 --T_in 3 --T_inv 7  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1000 --contr_loss False
python main.py --task sin  --Ntrain 100 --Nvalid 25 --Ntest 25 --T_in 7 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 0 --Nepoch 1000 --contr_loss False

e: sin with GP-ODE
python main.py --task sin --solver dopri5 --de SVGP --lengthscale 1.5 --variance 0.7  --Ntrain 80 --Nvalid 25 --Ntest 25 --batch_size 10 --T_in 3 --T_inv 10  --ode_latent_dim 4 --inv_latent_dim 4 --Nepoch 1500


############## LV ##############
lv data (clean atm)
a: --Ntrain 500 --T_inv 40 
python main.py --task lv --Ntrain 500 --Nvalid 100 --Ntest 100 --batch_size 20 --T_in 8 --T_inv 40  --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 2000
python main.py --task lv --Ntrain 500 --Nvalid 100 --Ntest 100 --batch_size 20 --T_in 8 --T_inv 40  --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 2000 --contr_loss False
python main.py --task lv --Ntrain 500 --Nvalid 100 --Ntest 100 --batch_size 20 --T_in 40 --T_inv 20  --ode_latent_dim 8  --inv_latent_dim 0 --Nepoch 2000 --contr_loss False

    a:1 --Ntrain 500 --T_inv 20 (T_inv 20 not better)
    python main.py --task lv --Ntrain 500 --Nvalid 100 --Ntest 100 --batch_size 20 --T_in 8 --T_inv 20  --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 2000
    python main.py --task lv --Ntrain 500 --Nvalid 100 --Ntest 100 --batch_size 20 --T_in 8 --T_inv 20  --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 2000 --contr_loss False
    python main.py --task lv --Ntrain 500 --Nvalid 100 --Ntest 100 --batch_size 20 --T_in 20 --T_inv 20  --ode_latent_dim 8  --inv_latent_dim 0 --Nepoch 2000 --contr_loss False

b: --Ntrain 100  --T_inv 40 (100 is too few)
python main.py --task lv --Ntrain 100 --Nvalid 30 --Ntest 30 --batch_size 10 --T_in 8 --T_inv 40  --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 2000
python main.py --task lv --Ntrain 100 --Nvalid 30 --Ntest 30 --batch_size 10 --T_in 8 --T_inv 40  --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 2000 --contr_loss False
python main.py --task lv --Ntrain 100 --Nvalid 30 --Ntest 30 --batch_size 10 --T_in 40 --T_inv 20  --ode_latent_dim 8  --inv_latent_dim 0 --Nepoch 2000 --contr_loss False

    b:1 --Ntrain 250  --T_inv 40 (250 works but also maybe too few, try a little higher)
    python main.py --task lv --Ntrain 250 --Nvalid 50 --Ntest 50 --batch_size 15 --T_in 8 --T_inv 40  --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 2000
    python main.py --task lv --Ntrain 250 --Nvalid 50 --Ntest 50 --batch_size 15 --T_in 8 --T_inv 40  --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 2000 --contr_loss False
    python main.py --task lv --Ntrain 250 --Nvalid 50 --Ntest 50 --batch_size 15 --T_in 40 --T_inv 20  --ode_latent_dim 8  --inv_latent_dim 0 --Nepoch 2000 --contr_loss False

    b) 2. Ntrain 400  batch_size 20 T_inv 40
     (if this looks better than Ntrain 500) then put on b) 3.
    python main.py --task lv --Ntrain 400 --Nvalid 80 --Ntest 80 --batch_size 20 --T_in 8 --T_inv 40  --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 2000
    python main.py --task lv --Ntrain 400 --Nvalid 80 --Ntest 80 --batch_size 20 --T_in 8 --T_inv 40  --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 2000 --contr_loss False
    python main.py --task lv --Ntrain 400 --Nvalid 80 --Ntest 80 --batch_size 20 --T_in 40 --T_inv 20  --ode_latent_dim 8  --inv_latent_dim 0 --Nepoch 2000 --contr_loss False

    b) 2.i Ntrain 400  batch_size 20 T_inv 40 beta for contr_loss (b = 10)
    python main.py --task lv --beta_contr 10 --Ntrain 400 --Nvalid 80 --Ntest 80 --batch_size 20 --T_in 8 --T_inv 40  --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 2000
    python main.py --task lv --beta_contr 10 --Ntrain 400 --Nvalid 80 --Ntest 80 --batch_size 20 --T_in 8 --T_inv 40  --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 2000 --contr_loss False
    python main.py --task lv --beta_contr 10 --Ntrain 400 --Nvalid 80 --Ntest 80 --batch_size 20 --T_in 40 --T_inv 20  --ode_latent_dim 8  --inv_latent_dim 0 --Nepoch 2000 --contr_loss False

    b) 3. Ntrain 400 batch_size 15 T_inv 30 (if b)2. good) 



c:  --Ntrain 100  --T_inv 20
python main.py --task lv --Ntrain 100 --Nvalid 30 --Ntest 30 --batch_size 10 --T_in 8 --T_inv 20  --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 2000
python main.py --task lv --Ntrain 100 --Nvalid 30 --Ntest 30 --batch_size 10 --T_in 8 --T_inv 20  --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 2000 --contr_loss False
python main.py --task lv --Ntrain 100 --Nvalid 30 --Ntest 30 --batch_size 10 --T_in 20 --T_inv 20  --ode_latent_dim 8  --inv_latent_dim 0 --Nepoch 2000 --contr_loss False

    c:1. --Ntrain 250  --T_inv 20
    put on depending on above results

############## ROT MNIST ##################
python main.py --task rot_mnist --Ntrain 500 --Nvalid 60 --Ntest 60 --batch_size 20 --cnn_arch cnn  --T_in 1 --T_inv 16 --ode_latent_dim 10 --inv_latent_dim 16 --Nepoch 1000 #result 16-01-2023-15:58
python main.py --task rot_mnist --Ntrain 500 --Nvalid 60 --Ntest 60 --batch_size 20 --cnn_arch cnn  --T_in 1 --T_inv 16 --ode_latent_dim 10 --inv_latent_dim 16 --Nepoch 1000 --contr_loss False
python main.py --task rot_mnist --Ntrain 500 --Nvalid 60 --Ntest 60 --batch_size 20 --cnn_arch cnn  --T_in 1 --T_inv 16 --ode_latent_dim 10 --inv_latent_dim 0 --Nepoch 1000 --contr_loss False

b: increase T_in 5 for Neural ODE (still looks worse keep at T_in 5 so more fair comparison)
python main.py --task rot_mnist --Ntrain 500 --Nvalid 60 --Ntest 60 --batch_size 20 --cnn_arch cnn  --T_in 5 --T_inv 16 --ode_latent_dim 10 --inv_latent_dim 0 --Nepoch 1000 --contr_loss False

c: change solver to dopri5
python main.py --task rot_mnist --solver dopri5 --Ntrain 500 --Nvalid 60 --Ntest 60 --batch_size 20 --cnn_arch cnn  --T_in 1 --T_inv 16 --ode_latent_dim 10 --inv_latent_dim 16 --Nepoch 1000 
python main.py --task rot_mnist --solver dopri5 --Ntrain 500 --Nvalid 60 --Ntest 60 --batch_size 20 --cnn_arch cnn  --T_in 1 --T_inv 16 --ode_latent_dim 10 --inv_latent_dim 16 --Nepoch 1000 --contr_loss False
python main.py --task rot_mnist --solver dopri5 --Ntrain 500 --Nvalid 60 --Ntest 60 --batch_size 20 --cnn_arch cnn  --T_in 5 --T_inv 16 --ode_latent_dim 10 --inv_latent_dim 0 --Nepoch 1000 --contr_loss False

change content : few-shot learning 


############# MOVING MNIST ######################
moving mnist (seq_len specifies that training data uses 15 time frames)
a: check content variable ida 
b: dimensionality of content variable 64
python main.py --task mov_mnist --Ntrain 1500 --Nvalid 100 --Ntest 100 --batch_size 25 --seq_len 15 --cnn_arch dcgan --T_in 5 --T_inv 15 --ode_latent_dim 12 --inv_latent_dim 64 --Nepoch 2000
python main.py --task mov_mnist --Ntrain 1500 --Nvalid 100 --Ntest 100 --batch_size 25 --seq_len 15 --cnn_arch dcgan --T_in 5 --T_inv 15 --ode_latent_dim 12 --inv_latent_dim 64 --Nepoch 2000 --contr_loss False
python main.py --task mov_mnist --Ntrain 1500 --Nvalid 100 --Ntest 100 --batch_size 25 --seq_len 15 --cnn_arch dcgan --T_in 10 --T_inv 15 --ode_latent_dim 12 --inv_latent_dim 0 --Nepoch 2000 --contr_loss False


b: dimensionality of content variable 32 + beta_conr 10 
python main.py --task mov_mnist --beta_contr 10 --Ntrain 1500 --Nvalid 100 --Ntest 100 --batch_size 25 --seq_len 15 --cnn_arch dcgan --T_in 5 --T_inv 15 --ode_latent_dim 12 --inv_latent_dim 32 --Nepoch 2000



python main.py --task mov_mnist --Ntrain 1500 --Nvalid 50 --Ntest 50 --seq_len 15 --cnn_arch dcgan --T_in 5 --T_inv 15 --ode_latent_dim 12 --inv_latent_dim 32 --Nepoch 2500
python main.py --task mov_mnist --Ntrain 1500 --Nvalid 50 --Ntest 50 --seq_len 15 --cnn_arch dcgan --T_in 5 --T_inv 15 --ode_latent_dim 12 --inv_latent_dim 64 --Nepoch 2500

python main.py --task mov_mnist --Ntrain 500 --Nvalid 40 --subsample 50 --seq_len 15 --cnn_arch dcgan --T_in 5 --T_inv 15 --Nepoch 2500



############# SPIRAL ########################
spiral data --> Cagatay checks the data
python main.py --task spiral --Ntrain 800 --Nvalid 50 --T_in 8 --T_inv 40 --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 3000
python main.py --task spiral --Ntrain 800 --Nvalid 50 --T_in 8 --T_inv 40 --ode_latent_dim 8  --inv_latent_dim 8 --Nepoch 3000 --contr_loss False
python main.py --task spiral --Ntrain 800 --Nvalid 50 --T_in 40 --T_inv 40 --ode_latent_dim 8  --inv_latent_dim 0 --Nepoch 3000 --contr_loss False
